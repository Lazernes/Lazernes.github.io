---
title: "6장 일반적인 머신 러닝 워크플로"
excerpt: "머신 러닝 문제에 접근하고 해결하는 데 사용할 수 있는 일반적인 단계별 청사진에 대해 알아본다."

wirter: Myeongwoo Yoon
categories:
  - Deep Learning with Python
tags:
  - Deep Learning
  - Python

toc: true
toc_sticky: true
use_math: true
 
date: 2024-12-06
last_modified_at: 2024-12-06
---

&ensp;머신 러닝의 일반적인 워크플로는 크게 세 부분으로 구성된다.
* 작업 정의
  - 문제 영역과 고객의 요청 이면에 있는 비즈니스 로직을 이해
  - 데이터를 수집하고, 데이터가 드러내는 내용을 이해하고, 작업의 성공을 측정하는 방법을 선택
* 모델 개발
  - 머신 러닝 모델로 처리할 수 있는 데이터를 준비하고, 모델 평가 방법과 간단한 기준점을 선택하고, 일반화 성능을 가지며 과대적합할 수 있는 첫 번째 모델을 훈련
  - 그다음 가능한 최대의 일반화 성능에 도달할 때까지 모델에 규제를 추가하고 튜닝
* 모델 배포
  - 작업 결과를 고객에서 제시

작업 정의
======

&ensp;무엇을 하는지 자세히 이해하지 못하면 좋은 결과를 만들 수 없다.

문제 정의
------

&ensp;머신 러닝 문제를 정의하려면 일반적으로 고객과 많은 세부 논의가 필요하다. 다음은 가장 우선 순위가 높아야 할 질문이다.
* 입력 데이터는 무엇인가? 어떤 것을 예측하려고 하나?
  - 가용할 훈련 데이터가 있어야 어떤 것을 예측하도록 학습할 수 있음
* 당귀한 문제가 어떤 종류인가?
  - 이진 분류, 다중 분류, 스칼라 회귀, 벡터 회귀, 다중 레이블 다중 분류, 이미지 분할, 랭킹, 군집, 생성, 강화 학습
  - 어떤 경우에는 머신 러닝이 데이터를 이해하는 최선의 방법이 아니고 통계 분석과 같은 다른 방법을 사용해야 할 수도 있음
* 기존 솔루션은 어떤 것이 있나?
  - 어떤 시스템이 어떻게 일하고 있는지 이해해야 함.
* 고려해야 할 특별한 제약이 있나?
  - 작업이 충족시켜야 할 조건을 완벽하게 이해해야 함

&ensp;조사를 수행하고 나면 입력과 타깃이 무엇이고, 큰 범위에서 어떤 종류의 머신 러닝 작업이 이 문제에 맞는지 알게된다. 이 단계에서 만든 가설은 다음과 같다.
* 주어진 입력으로 타깃을 예측할 수 있다고 가정
* 가용한 데이터(곧 수집할 데이터)에 입력과 출력 사이의 관계를 학습하는 데 충분한 정보가 있다고 가정

&ensp;작동하는 모델을 얻기까지 이는 가설에 불가하다. 검증될지 아닐지 기다려 보아야 한다. 모든 문제가 머신 러닝으로 해결되지는 않는다.

데이터 수집
------

&ensp;작업 특성을 이해하고, 입력과 타깃이 무엇인지 알게 되면 데이터를 수집할 체례이다. 대부분의 머신 러닝 프로젝트에서 가장 힘들고 시간이 많이 걸리며 비용이 많이 드는 단계이다. 좋은 데이터셋은 관리하고 투자할 가치가 있는 자산이다.<br/><br/>
**데이터 애너테이션 인프라에 투자하기**<br/>
&ensp;데이터 애너테이션 과정이 타깃의 품질을 결정하여 결과적으로 모델의 품질을 결정할 것이다. 직접 데이터에 애너테이션을 수행하야 하나, 레이블을 모으기 위해 미케니컬 터크(Mechanical Turk) 같은 크라우드소싱(crowdsourcing) 플랫폼을 사용해야 하나, 전문적인 데이터 레이블링 회사의 서비스를 사용해야 하는지 등 어떤 방법을 사용할 수 있는지 신중하게 고려해야 한다.<br/>
&ensp;아웃소싱은 잠재적으로 시간과 비용을 절약할 수 있지만 통제권이 넘어간다. 미케니컬 테크 같은 서비스는 비용이 많이 들지 않고 쉽게 규모를 확장할 수 있지만 애너테이션에 잡음이 꽤 들어갈 수 있다.<br/>
&ensp;최선의 옵션을 고르기 위해 현재 작업의 제약 조건을 고려해야 한다.
* 데이터에 레이블을 할당할 사람이 해당 분야의 전문가야 하나? 아니면 아무나 레이블을 달 수 있나?
* 데이터 애너테이션에 전문적인 지식이 필요하다면 이를 위해 사람을 훈련시킬 수 있나? 그렇지 않다면 관련된 전문가를 구할 수 있나?
* 전문가의 애너테이션 작업을 이해하고 있나?
  - 그렇지 않으면 데이터셋을 블랙박스처럼 다루어야 하므로 수동으로 특성 공학을 수행할 수 없음
  - 이것이 치명적이지는 않지만 제약이 될 수 있음

&ensp;내부에서 데이터 레이블을 만들기로 결정했다면 애너테이션 작업을 위해 어떤 소프트웨어를 사용할 것인지 자문해본다. 직접 이런 소프트웨어를 개발해야 할 수도 있다. 생산적인 데이터 애너테이션 소프트웨어를 사용하면 많은 시간을 절약할 수 있으므로 프로젝트 초기에 투자할 가치가 있다.<br/><br/>
**대표성 없는 데이터 주의하기**<br/>
&ensp;머신 러닝 모델은 이전에 본 샘플과 비슷한 입력만 이해할 수 있다. 훈련에 사용하는 데이터가 제품 환경에 있는 데이터를 대표하는 것이 중요하다. 이런 고려 사항이 모든 데이터 수집 작업에 근간이 되어야 한다. 즉, 훈련 데이터가 제품 환경의 데이터를 대표하지 못하면 안된다.<br/>
&ensp;가능하다면 모델이 사용될 환경에서 직접 데이터를 수집해야 한다. 제품 환경에서 수집한 데이터로 훈련하는 것이 불가능하다면 훈련 데이터와 실전 데이터 사이의 차이점을 완전히 이해햐고, 이런 차이점을 좁히기 위해 적극적으로 노력해야 한다.<br/>
&ensp;이와 관련된 현상으로 **개념 이동(concept drift)**을 알고 있어야 한다. 거의 모든 실전 문제에서 개념 이동을 만나게 된다. 특히 사용자가 생성한 데이터를 다루는 경우 개념 이동은 제품 환경에서 데이터의 속성이 시간에 따라 변할 때 일어난다. 이로 인해 모델의 정확도가 점진적으로 감소한다. 예를 들어 어휘, 표현 등이 시간에 따라 변하기 때문이다. 개념 이동은 부정한 패턴이 매일 바뀌는 신용 카드 부정 거래 감지와 같은 적대적인 상황에서 특히 심각하다. 빠르게 변하는 개념 이동에 대처하려면 지속적인 데이터 수집, 애너테이션, 모델 재훈련이 필요하다.<br/>
&ensp;머신 러닝은 훈련 데이터에 있는 패턴을 기억하는 데만 사용할 수 있다. 이전에 보았던 것만 인식할 수 있다. 미래를 예측하기 위해 과거 데이터에서 훈련한 머신 러닝 모델을 사용하는 것은 미래가 과거처럼 움직인다고 가정한 것이다. 하지만 그렇지 않은 경우가 많다.<br/>
&ensp;특별히 교활하고 자주 발생하는 대표성이 없는 데이터의 사례는 **샘플링 편향(sampling bias)**이다. 샘플링 편향은 데이터 수집 과정이 예측 대상과 상호 작용하여 편향된 측정 결과를 만들 때 일어난다.

데이터 이해
------

&ensp;데이터셋을 블랙박스처럼 다루는 것은 상당히 나쁜 방법이다. 모델 훈련을 시작하기 전에 데이터를 탐색하고 시각화하여 예측 능력을 가진 특성에 대한 통찰을 얻어야 한다. 이를 통해 특성 공학에 대한 정보를 얻고 가능성 있는 문제를 걸러 낼 수 있다.
* 데이터가 이미지나 자연어 텍스트를 포함하고 있다면 몇 개의 샘플(레이블)을 직접 확인해 본다.
* 데이터가 수치 특성을 포함하고 있다면 특성 값의 히스토그램을 그려서 값의 범위나 빈도를 파악하는 것이 좋음
* 데이터가 위치 정보를 포함하고 있다면 지도에 그러본뒤 뚜렷한 패턴이 드러나는지 봄
* 일부 샘플이 어떤 특성에 대해 누락된 값을 가지고 있는지, 그렇다면 데이터를 준비할 때 이를 처리해야 함
* 작업이 분류 문제라면 데이터에 있는 각 클래스의 샘플 개수를 출력해 본다. 클래스의 샘플 개수가 거의 비슷한지, 그렇지 않으면 이런 불균형을 고려해야 함
* **타깃 누출(target leaking)**을 확인해 데이터에 타깃에 관한 정보를 제공하는 특성이 있는지 확인
  - 데이터에 있는 모든 특성이 제품 환경에도 동일한 형태로 제공될 수 있는지 항상 자문해 보아야 함.

성공 지표 선택
------

&ensp;어떤 것을 제어하려면 관측할 수 있어야 한다. 프로젝트에서 성공하기 위해서는 먼저 성공이 무엇인가를 정의해야 한다. 정확도인지, 정밀도나 재현율인지, 고객 재방문인지 성공의 지표가 프로젝트 전반에 걸쳐 내리는 모든 기술적 선택을 안내할 것이다. 고객의 비즈니스 성공처럼 고수준의 목표와 직접적으로 연결되어 있어야 한다.<br/>
&ensp;클래스 분포가 균일한 분류 문제에서는 정확도와 ROC(Receiver Operating Characteristic) 곡선 아래의 면적인 ROC AUG가 일반적인 지표이다. 클래스 분포가 균일하지 않은 문제나 랭킹 문제, 다중 레이블 문제에는 정밀도와 재현율을 사용할 수 있다. 또는 정확도나 ROC AUG의 가중치 평균을 사용할 수 있다.

모델 개발
======

&ensp;진행 과정을 측정할 방법을 찾았다면 모델 개발을 시작할 수 있다. 대부분의 튜토리얼과 연구 프로젝트는 이 단계만 수행한다. 즉, 문제 정의와 데이터 수집은 이미 완료되었다고 가정하고, 모델 배포와 유지 관리는 다른 사람이 처리한다고 가정하고 건너뛴다. 

데이터 준비
------

&ensp;이전에 배웠듯이 딥러닝 모델은 일반적으로 원시 데이터를 사용하지 않는다. 데이터 전처리 목적은 주어진 원본 데이터를 신경망에 적용하기 쉽도록 만드는 것이다. 여기에는 벡터화(vectorization), 정규화(normalization), 누락된 값 다루기 등이 포함된다. 많은 전처리 기법은 도레인에 특화되어 있다.<br/><br/>
**벡터화**<br/>
&ensp;신경망에서 모든 입력과 타깃은 일반적으로 부동 소수점 데이터로 이루어진 텐서여야 한다(또는 특정 경우에 정수나 문자열로 이루어진 텐서). 처리해야 할 것이 무엇이든지 먼저 텐서로 변환해야 한다. 이 단계를 **데이터 벡터화(data vectorization)**라고 한다.<br/><br/>
**값 정규화**<br/>
&ensp;일반적으로 비교적 큰 값이나 균일하지 않은 데이터를 신경망에 주입하는 것은 위험하다. 이렇게 하면 업데이트할 그레디언트가 커져 네트워크가 수렴하는 것을 방해한다. 네트워크를 쉽게 학습시키려면 데이터가 다음 특징을 따라야 한다.
* **작은 값을 취함**: 일반적으로 대부분의 값이 0~1 사이여야 함
* **균일해야 함**: 모든 특성이 대체로 비슷한 범위를 가져야 함

&ensp;추가적으로 다음에 나오는 조금 더 엄격한 정규화 방법이 많이 사용되고 도움이 될 수 있지만 항상 필요하지는 않다.
* 각 특성별로 평균이 0이 되도록 정규화
* 각 특성별로 표준 편차가 1이 되도록 정규화

**누락된 값 처리하기**<br/>
&ensp;데이터에 값이 누락된 경우가 있다. 어떤 특성이 모든 샘플에 들어 있지 않으면 훈련 데이터나 테스트 데이터에 누락된 값이 포함된다. 이 특성을 완전히 삭제할 수 있지만 반드시 그럴 필요는 없다.
* 범주형 특성이라면 '누락된 값'이라는 의미의 새로운 범주를 만드는 것이 안전
  - 모델이 타깃에 대해 이것이 의미하는 바를 자동으로 학습할 것이다.
* 수치형 특성이라면 '0'같은 임의의 값을 넣지 않도록 함
  - 특성이 만드는 잠재 공간에 불연속성을 만들어 이런 데이터에서 훈련한 모델이 일반화되기 어려울 수 있기 때문
  - 그 대신 누락된 값을 해당 특성의 평균이나 중간 값으로 대체하는 것을 고려
  - 또는 다른 특성 값에서 누락된 특성 값을 예측하는 모델을 훈련할 수도 있음

&ensp;테스트 데이터에 범주형 특성이 누락될 가능성이 있다고 가정하면, 네트워크가 누락된 값이 없는 데이터에서 훈련되었다면 이 네트워크는 누락된 값을 무시하는 법을 알지 못한다. 이런 경우에는 누락된 값이 있는 훈련 샘플을 고의적으로 만들어야 한다. 훈련 샘플의 일부를 여러 벌 복사해서 테스트 데이터에서 누락될 것 같은 범주형 특성을 제거한다.

평가 방법 선택
------

&ensp;모델의 목적은 일반화를 달성하는 것이다. 모델 개발 전반에 걸친 모든 모델링 결정은 일반화 성능을 측정하는 검증 지표에 의해 내려진다. 검증 과정의 목표는 실전 제품 환경에서 어떤 성공 지표를 사용할지 정확하게 추정하는 것이다. 이 과정의 신뢰성은 유용한 모델을 만드는 데 매우 중요하다.<br/>
&ensp;홀드아웃 검증, K-겹 교차 검증, 반복 K-겹 교차 검증 중 하나를 선택하면 된다. 대부분의 경우 첫 번째로 충분하다. 검증 세트의 대표성을 항상 유념해야 한다. 또한 훈련 세트와 검증 세트 간에 중복된 샘플이 없도록 주의한다.

기준 모델 뛰어넘기
------

&ensp;모델을 다루기 시작할 때 초기 목표는 **통계적 검정력(statistical power)**을 달성하는 것이다. 즉, 아주 간단한 기준점을 넘을 수 있는 작은 모델을 개발하는 것이다. 이 단계에서 가장 중요하게 중점을 둘 세가지는 다음과 같다.
* 특성 공학: 유용하지 않은 특성을 제외하고, 문제에 대한 지식을 사용하여 유용할 것 같은 새 특성을 개발
* 구조에 대한 올바른 가정: 어떤 종류의 모델 구조를 사용할 것인가, 밀집 연결 신경망, 합성곱 신경망, 순환 신경망 또는 트랜스포머를 사용하나, 딥러닝이 이 작업에 좋은 접근 방법인가, 또는 다른 방식을 사용해야 하나
* 좋은 훈련 옵션 선택: 어떤 손실 함수를 사용해야 하나, 배치 크기와 학습률을 얼마로 해야 하나

&ensp;대부분의 경우 시작할 때 활용할 수 있는 기존 탬플릿이 있다. 주어진 작업에 잘 맞는 특성 공학 기법과 모델 구조를 찾기 위해 선행 기술을 조사한다. 통계적 검정력을 달성하는 것이 항상 가능하지는 않다. 여러 개의 타당성 있는 네트워크 구조를 시도해 보고 간단한 기준점을 넘어서지 못한다면 입력 데이터에 존재하지 않는 것을 얻으려고 한다는 신호일 것이다. 다음과 같이 2개의 가설이 있다는 것을 알아야 한다.
* 주어진 입력으로 타깃을 예측할 수 있다고 가정
* 가용한 데이터에 입력과 출력 사이의 관계를 학습하는 데 충분한 정보가 있다고 가정

&ensp;이 가설이 잘못된 것일 수 있다. 이때는 처음으로 다시 돌아가야 한다.

모델 용량 키우기: 과대적합 모델 만들기
------

&ensp;통계적 검정력을 가진 모델을 얻었다면 이제 주어진 문제를 적절히 모델링하기에 충분한 층과 파라미터가 있는지 등 충분히 성능을 내는지 알아봐야 한다. 머신 러닝은 과소적합과 과대적합 사이, 즉 과소용량과 과대용량의 경계에 있는 모델이 이상적이다. 이 경계가 어디에 놓여 있는지 알기 위해서는 먼저 지나처 보아야 한다.<br/>
&ensp;얼마나 큰 모델을 만들어야 하는지 알기 위해서는 과대적합된 모델을 만들어야 한다. 이는 층을 추가하거나 층의 크기를 바꾸거나 더 많은 애포크 동안 훈련하면 된다. 괌심 대상인 훈련과 검증 지표는 물론 훈련 손실과 검증 손실을 모니터링하고 검증 데이터에서 모델 성능이 감소하기 시작했을 때 과대적합에 도달한 것이다.

모델 규제와 하이퍼파라미터 튜닝
------

&ensp;통계적 검정력을 달성하고 과대적합할 수 있다면 올바른 방향으로 가조 있는 것이다. 이제 목표는 일반화 성능을 최대화하는 것이다.<br/>
&ensp;이 단계가 대부분의 시간을 차지한다. 반복적으로 모델을 수정하고 훈련하고 검증 데이터에서 평가한다. 그리고 다시 수정하고 가능한 좋은 모델을 얻을 때까지 반복한다. 다음과 같은 것들을 시도해 보아야 한다.
* 다른 구조를 시도. 층을 추가하거나 제거
* 드롭아웃을 추가
* 모델이 작다면 L1이나 L2 규제를 추가
* 최적의 설정을 찾기 위해 하이퍼파라미터를 바꾸어 시도
* 선택적으로 데이터 큐레이션이나 특성 공학을 시도.
  - 더 많은 데이터를 수집, 애너테이션을 만들고, 더 나은 특성을 개발, 유용하지 않을 것 같은 특성을 제거

&ensp;케라스 튜너(Keras Tuner)같은 자동화된 하이퍼파라미터 튜닝 소프트웨어를 사용해서 이런 작업의 많은 부분을 자동화할 수 있다.<br/>
&ensp;검증 과정에서 얻은 피드백을 사용하여 모델을 튜닝할 때마다 검증 과정에 대한 정보를 모델에 누설하고 있다는 것을 유념해야 한다. 몇 번 반복하는 것은 큰 문제가 되지 않지만, 많이 반복하게 되면 결국 모델이 검증 과정에 과대적합될 것이다. 이는 검증 과정의 신뢰도를 감소시킨다.<br/>
&ensp;만족할 만한 모델 설정을 얻었다면 가용한 모든 데이터를 사용해서 제품에 투입할 최종 모델을 훈련시킨다. 마지막에 딱 한번 테스트 세트에서 평가한다. 테스트 세트의 성능이 검증 데이터에서 측정한 것보다 많이 나쁘다면, 검증 과정에 전혀 신뢰성이 없거나 모델의 하이퍼파라미터를 튜닝하는 동안 검증 데이터에 과대적합된 것이다. 이런 경우에는 좀 더 신뢰할 만한 평가 방법으로 바꾸는 것이 좋다.

모델 배포
======

&ensp;모델이 테스트 세트를 사용한 최종 평가를 성공적으로 통과되었다면 이 모델을 배포하여 제품으로 운영될 준비가 된 것이다.
* Rest API로 모델 배포하기
  - 가장 보편적인 방법
  - 서버나 클라우드 인스턴스에 텐서플로를 설치하고 REST API로 모델의 예측을 요청
* 장치로 모델 배포하기
  - 모델을 애플리케이션이 실행되는 동일한 장치에서 구동해야할 필요가 있을때 사용
* 브라우저에 모델 배포하기
* 추론 모델 최적화