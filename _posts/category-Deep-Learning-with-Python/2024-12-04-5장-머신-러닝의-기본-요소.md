---
title: "5장 머신 러닝의 기본 요소"
excerpt: "정확한 모델 평가의 중요성 및 훈련과 일반화 사이의 균형을 알아본다."

wirter: Myeongwoo Yoon
categories:
  - Deep Learning with Python
tags:
  - Deep Learning
  - Python

toc: true
toc_sticky: true
use_math: true
 
date: 2024-12-04
last_modified_at: 2024-12-04
---

일반화: 머신 러닝의 목표
======

&ensp;머신 러닝의 근본적인 이슈는 최적화와 일반화 사이의 줄다리기이다.
* **최적화(optimization)**: 가능한 훈련 데이터에서 최고의 성능을 얻으려고 모델을 조정하는 과정(머신 러닝에서 학습에 해당)
* **일반화(generalization)**: 훈련된 모델이 이전에 본 적 없는 데이터에서 얼마나 잘 수행되는지 의미

&ensp;목표는 좋은 일반화 성능을 얻는 것이다. 하지만 일반화 성능을 제어할 벙법이 없다. 단지 모델을 훈련 데이터에 맞출 수만 있다. 만약 너무 잘 맞는다면 과대적합이 시작되고 일반화 성능은 나빠진다.

과소적합과 과대적합
------

&ensp;전형적인 과대접합 진행과정은 다음과 같다.<br/>
<p align="center"><img src="/assets/img/Deep Learning with Python/5장 머신 러닝의 기본 요소/1-1-전형적인 과대적합 진행 과정.png" width="400"></p>

&ensp;훈련 초기에 최적화와 일반화는 상호 연관되어 있다. 훈련 데이터의 손실이 낮아질수록 테스트 데이터의 손실도 낮아진다. 이런 상황이 발생할 때 모델이 **과소적합(underfitting)**되었다고 말한다. 모델의 성능이 계속 발전될 여지가 있다. 즉, 네트워크가 훈련 데이터에 있는 모든 관련 패턴을 학습하지 못했다. 하지만 훈련 데이터에서 훈련을 특정 횟수만큼 반복하고 난 후에는 일반화 성능이 더 이상 높아지지 않으며 검증 세트의 성능이 멈추고 감소되기 시작한다. 즉, 모델이 과대적합되기 시작한다. 이는 훈련 데이터에 특화된 패턴을 학습하기 시작했다는 의미이다. 이 패턴은 새로운 데이터와 관련성이 적고 잘못된 판단을 하게 만든다.<br/>
&ensp;과대적합은 데이터에 잡음이 있거나, 불확실성이 존재하거나, 드문 특성이 포함되어 있을 때 특히 발생할 가능성이 높다.<br/><br/>
**잡음 섞인 훈련 데이터**<br/>
&ensp;실제 데이터셋에는 잘못된 입력이 있는 경우가 흔하다. 예를 들어 MNIST 숫자의 경우 이상한 이미지나 전부 검은식인 이미지가 있을 수 있다. 또한 더 안 좋은 완전히 정상적인 이미지인데 레이블이 잘못된 이미지가 있을 수 있다.<br/>
&ensp;모델을 이런 이상치에 맞추려고 하면 다음과 같이 일반화 성능이 감소된다.<br/>
<p align="center"><img src="/assets/img/Deep Learning with Python/5장 머신 러닝의 기본 요소/1-2-일반화 성능 감소.png" width="400"></p>

**불확실한 특성**<br/>
&ensp;모든 데이터 잡음이 부정확성 때문에 발생하는 것은 아니다. 문제에 불확실성과 모호성이 있다면 왁변하고 깔끔하게 레이블이 부여된데이터라도 잡음이 있을 수 있다. 분류 작업에서 입력 특성 공간의 일부 영역이 동시에 여러 클래스에 연관된 경우가 종종있다.<br/>
&ensp;모델이 다음과 같이 특성 공간의 모호한 영역에 너무 확신을 가지면 이런 확률적인 데이터에 과대적합될 수 있다. 최적집합은 개별 데이터 포인트를 무시하고 더 큰 그림을 바라보아야 한다.<br/>
<p align="center"><img src="/assets/img/Deep Learning with Python/5장 머신 러닝의 기본 요소/1-3-특성 공간에 모호한 영역이 있을 때.png" width="400"></p>

**드문 특성과 가짜 상관관계**<br/>
&ensp;평생 두 마리의 주황색 얼룩무늬 고양이만 보았고 둘 다 사교성이 매우 없다면, 주황색 얼룩무늬 고양이는 일반적으로 사요적이지 않다고 추측할 수 있다. 이것이 과대적합이다. 더 많은 주황색 고양이와 다양한 다른 종류의 고양이를 보았다면 고양이 색이 성격과 관련이 없다믄 것을 배웠을 것이다. 비슷하게 드문 특성 값을 포함한 데이터셋에서 훈련한 머신 러닝 모델은 과대적합될 가능성이 매우 높다.<br/>
&ensp;훈련 데이터에서 100개의 샘플에 등장하는 단어가 있고, 그 샘플 중 54%는 긍정이고 46%는 부정이라고 가정하면, 이 차이는 통계적으로 완전히 우연일 수 있지만 모델은 분류 작업에 이 특성을 활용할 가능성이 높다. 이것이 과대적합의 가장 보편적인 원인 중 하나이다.<br/>
&ensp;MNIST의 기존 데이터의 784차원에 백색 잡음인 784개의 차원을 연결하여 새로운 훈련 세트 예를 하나 만들어본다. 따라서 데이터 셋의 절반은 잡음이다. 비교를 위해 모두 0인 784개의 차원을 연결하여 동일한 데이터셋을 만든다. 의미 없는 특성의 연결은 데이터의 기존 정보에 전혀 영향을 미치지 않는다. 즉, 무언가 추가만 한 것이다.
```python
from tensorflow.keras.datasets import mnist
import numpy as np

(train_images, train_labels), _ = mnist.load_data()
train_images = train_images.reshape((60000, 28 * 28))
train_images = train_images.astype('float32') / 255
train_images_with_noise_channels = np.concatenate(
    [train_images, np.random.random((len(train_images), 784))], axis=1)
train_images_with_zeros_channels = np.concatenate(
    [train_images, np.zeros((len(train_images), 784))], axis=1)
```

&ensp;이 두 훈련 세트에서 2장의 모델을 훈련해 본다.
```python
from tensorflow import keras
from tensorflow.keras import layers

def get_model():
  model = keras.Sequential([
    layers.Dense(512, activation="relu"),
    layers.Dense(10, activation="softmax")
  ])
  model.compile(optimizer="rmsprop",
                loss="sparse_categorical_crossentropy",
                metrics=["accuracy"])
  return model

model = get_model()
history_noise = model.fit(
    train_images_with_noise_channels, train_labels,
    epochs=10,
    batch_size=128,
    validation_split=0.2
)

model = get_model()
history_zeros = model.fit(
    train_images_with_zeros_channels, train_labels,
    epochs=10,
    batch_size=128,
    validation_split=0.2
)
```

&ensp;시간에 따라 각 모델의 검증 정화도가 어떻게 변하는지 비교해본다.
```python
import matplotlib.pyplot as plt

val_acc_noise = history_noise.history["val_accuracy"]
val_acc_zeros = history_zeros.history["val_accuracy"]
epochs = range(1, 11)
plt.plot(epochs, val_acc_noise, "b-", label="Validation accuracy with noise channels")
plt.plot(epochs, val_acc_zeros, "b--", label="Validation accuracy with zeros channels")
plt.title("Effect of noise channels on Validation accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()
```

&ensp;두 경우 모두 동일한 정보를 가진 데이터이지만 잡음이 섞인 데이터에서 훈련된 모델의 검증 정확도가 1퍼센트 포인트 정도 낮다. 이는 순전히 가짜 상관관계의 영향 때문이다. 잡음을 더 많이 섞을수록 정확도는 더 감소될 것이다.<br/>
<p align="center"><img src="/assets/img/Deep Learning with Python/5장 머신 러닝의 기본 요소/1-4-검증 정확도에 대한 잡음의 영향.png" width="400"></p>

&ensp;잡음 특성은 필연적으로 과대적합을 유발시킨다. 따라서 특성이 모델에 유익한지 또는 모델을 혼란스럽게 만드는지 확실하지 않다면 훈련 전에 **특정 선택(feature selection)**을 수행하는 것이 일반적이다. 특성 선택을 하는 일반적인 방법은 가용한 각 특성에 대해 어떤 유용성 점수를 계산하는 것이다. 즉, 특성과 레이블 사이의 상호 의존 정보(mutual information)처럼 작업에 대해 특성이 얼마나 유익한지 측정한다. 그다음 일정 임계 값을 넘긴 특성만 사용한다. 이렇게 하면 앞선 예에서 백색 잡음이 걸러질 수 있다.

딥러닝에서 일반화의 본질
------

&ensp;딥러닝 모델에 관한 놀라운 사실은 표현 능력이 충분하다면 어떤 것에도 맞추도록 훈련할 수 있다는 것이다. MNIST 레이블을 섞은 후 모델은 훈련해본다. 입력과 뒤섞은 레이블 사이에 아무런 관계가 없지만 비교적 작은 모델에서도 훈련 손실이 잘 감소한다. 당연히 이런 상황에서 가능란 일반화가 없기 때문에 검증 손실은 시간이 지남에 따라 향상되지 않는다.
```python
(train_images, train_labels), _ = mnist.load_data()
train_images = train_images.reshape((60000, 28 * 28))
train_images = train_images.astype("float32") / 255

random_train_labels = train_labels[:]
np.random.shuffle(random_train_labels)

model = keras.Sequential([
    layers.Dense(512, activation="relu"),
    layers.Dense(10, activation="softmax")
])
model.compile(optimizer="rmsprop",
              loss="sparse_categorical_crossentropy",
              metrics=["accuracy"])
model.fit(train_images, random_train_labels,
          epochs=100,
          batch_size=128,
          validation_split=0.2)
```

&ensp;이렇게 MNIST 데이터를 사용하지 않고 백색 잡음으로 입력을 만들고 랜덤하게 레이블을 생성할 수도 있다. 모델 파라미터가 충분하다면 여기에서도 모델을 훈련할 수 있다. 파이썬 딕셔너리처럼 특정 입력을 외워 버리게 된다.<br/><br/>
**매니폴드 가설**<br/>
&ensp;전처리하기 전의 MNIST 분류기 입력은 28 X 28 크기의 정수 배열이며 0 ~ 255 사이의 값을 가진다. 가능한 전체 입력 갔의 가짓수는 $784^{256}$이다. 하지만 이런 입력 중 매우 적은 수만 유효한 MNIST 샘플이다. 실제 손글씨 숫자는 가능한 모든 28 X 28 unit8 배열로 이루어진 공간에서 아주 작은 부분 공간만 차지한다. 더군다나 이 부분 공간은 부모 공간에 랜덤하게 뿌려진 포인트의 집합이 아니라 매우 구조적이다.<br/>
&ensp;우선 유요한 손글씨 숫자의 부분 공간은 연속적이다. 하나의 샘플을 조금 수정해도 여전히 같은 손글씨 숫자로 인식할 수 있다. 게다가 유효한 부분 공간 안에 있는 모든 샘플은 이 부분 공간을 가로지르를 매끈한 경로로 연결되어 있다. 2개의 MNIST 숫자 A와 B를 무작위로 선택하면 A를 B로 변형시키는 연속적인 중간 이미지가 있다는 의미이다. 2개의 연속적인 중간 이미지는 다음과 같이 서로 매우 비슷하다. 두 클래스의 경계 부근에서는 모호한 모양이 조금 있겠지만 이런 모양도 여전히 숫자처럼 보일 것이다.<br/>
<p align="center"><img src="/assets/img/Deep Learning with Python/5장 머신 러닝의 기본 요소/1-5-한 숫자에서 다른 숫자로 점차 변형되는 여러가지 MNIST 샘플.png" width="400"></p>

&ensp;기술적으로 손글씨 숫자가 가능한 모든 28 X 28 unit8 배열로 이루어진 공간 안에서 **매니폴드(manifold)**를 형성한다고 말한다. 매니폴드는 국부적으로는 선형 공간과 비슷하게 보이는 부모 공간의 저차원 부분 공간이다. 예를 들어 평면상의 매끄러운 한 곡선은 2D 공간 안에 있는 1D 매니폴드이다.<br/>
&ensp;더 일반적으로 **매니폴드 가설(manifold hypothesis)**은 실제 세상의 모든 데이터가 고차원 공간 안에 있는 저차원 매니폴드에 놓여 있다고 가정한다. 이는 딥러닝이 작동하는 이유이다. 매니폴드 가설은 다음을 의미한다.
* 머신 러닝 모델은 가능한 입력 공간 안에서 비교적 간단하고 저차원이며, 매우 구조적인 부분 공간(잠재 매니폴드(latent manifold))만 학습한다.
* 이런 매니폴드 중 하나 안에서 두 입력 사이를 보간(interpolation)하는 것이 항상 가능한다.
  - 연속적인 경로를 따라 한 입력에서 다른 입력으로 변형할 때 모든 포인트가 이 매니폴드에 속함

&ensp;샘플 사이를 보간하는 능력은 딥러닝에서 일반화를 이해하는 열쇠이다.<br/><br/>
**일반화의 원천인 보간**<br/>
&ensp;다루는 데이터 포인트가 보간할 수 있다면 이전에 본 적 없는 포인트를 해당 매니폴드에서 가까이 놓인 다른 포인트와 연결하여 이해할 수 있다. 즉, 공간 안의 샌플만 사용해서 공간 전체를 이해할 수 있다. 이는 보간을 사용해서 빈 곳을 채울 수 있기 때문이다.다음과 같이 잠재 매니폴드에서 보간은 부모 공간에서의 선형 보간과 다르다. 예를 들어 2개의 MNIST 숫자 사이의 픽세를 평균하면 일반저긍로 유효한 숫자가 만들어지지 않는다.<br/>
<p align="center"><img src="/assets/img/Deep Learning with Python/5장 머신 러닝의 기본 요소/1-6-선형 보간과 잠재 매니폴드 보간.png" width="400"></p>

&ensp;근사적으로 학습된 데이터 매니폴드에서 보간을 통해 딥러닝의 일반화가 달성되지만 보간이 일반화의 전부라고 가정하는 것은 실수이다. 보간은 이전에 본 것과 매우 가까운 것을 이해하는 데 도움을 줄 수 있을 뿐이다. 이를 **지역 일반화(local generalization)**라고 한다. 놀랍게도 사람은 항상 극도로 새로운 것을 다루면서도 잘 처리한다.<br/>
&ensp;사람은 보간 이외의 인지 매커니즘으로 **궁극 일반화(extreme generalization)**를 할 수 있다. 인지 메커니즘은 추상화, 세상에 대한 상징적 모델, 추론, 논리, 상식, 일반적으로 이성이라고 부르는 세상에 대한 선천적 능력등을 말하며 직관이나 패턴 인식과는 다르다. 후자는 사실상 대체로 보간에 해당하지만 전자는 그렇지 않다. 둘 다 지능에 꼭 필요하다.<br/><br/>
**딥러닝이 작동하는 이유**<br/>
<p align="center"><img src="/assets/img/Deep Learning with Python/5장 머신 러닝의 기본 요소/1-7-복잡한 데이터 매니폴드 펼치기.png" width="400"></p>

&ensp;한 장의 종이는 3D 공간 안의 2D 매니폴드를 나타낸다. 딥러닝 모델은 종이 공을 펼치는 도구이다. 즉, 잠재 매니폴드를 풀기 위한 도구이다.<br/>
&ensp;딥러닝 모델은 근본적으로 미분할 수 있어야 하기 때문에 매끄럽고 연속적인 고차원의 곡선이다. 경사 하강법을 통해 이 곡선을 부드럽고 점진적으로 데이터 포인트에 맞춘다. 딥러닝은 본질적으로 곡선(매니폴드)을 선택하여 훈련 데이터 포인트에 맞을 때까지 파라미터를 점진적으로 조정하는 것이다.<br/>
&ensp;이 곡선은 어떤 것에도 맞출 수 있는 충분한 파라미터가 있다. 실제로 모델은 충분히 오래 훈련한다면 결국 훈련 데이터를 완전히 외워 버리게 되고 일반화가 전혀 되지 않을 것이다. 하지만 학습하려는 데이터는 해당 공간에 희소하게 분산된 독립적인 포인트로 구성되지 않는다. 이 데이터는 입력 공간 안에서 고도로 구조적인 저차원의 매니폴드를 형성한다. 이는 매니폴드 가설이다. 경사 하강법으로 시간이 지남에 따라 부드럽고 점진적으로 모델 곡선을 이 데이터에 맞춘다. 따라서 다음과 같이 모델이 데이터의 매니폴드를 대략적으로 근사하는 중간 지점이 있을 것이다.<br/>
<p align="center"><img src="/assets/img/Deep Learning with Python/5장 머신 러닝의 기본 요소/1-8-랜덤한 모델에서 최적적합 모델 얻기.png" width="400"></p>

&ensp;그 지점에서 모델이 학습한 곡선을 따라 이동하는 것은 데이터의 실제 잠재 매니폴드를 따라 이동하는 것과 비슷하다. 따라서 모델이 훈련 입력 사이를 보간하여 이전에 본 적 없는 입력을 이해할 수 있을 것이다.<br/>
&ensp;딥러닝 모델이 충분한 표현 능력을 가진다는 일반적인 사실 외에도 잠재 매니폴드를 학습하는데 특히 잘 맞는 몇 가지 속성이 있다.
* 딥러닝 모델은 입력에서부터 출력으로 매끄럽고 연속적인 매핑을 구현하므로 필수적으로 미분가능해야 하기 때문에 매끄럽고 연속적이어야 한다.
  - 이런 매끄러움은 동일한 속성을 가진 잠재 매니폴드를 근사하는 데 도움이 된다.
* 딥러닝 모델은 훈련 데이터에 있는 정보의 형태를 반영하는 식으로 구조화되는 경향이 있다. 더 일반적으로 심층 신경망은 학습한 표현을 계층적이고 모듈 방식으로 구조화된다.
  - 이는 자연적인 데이터가 구성되는 방식을 반영한 것이다.

**가장 중요한 훈련 데이터**<br/>
&ensp;딥러닝이 실제로 매니폴드 학습에 잘 맞지만 일반화의 능력은 모델의 어떤 속성 때문이라기보다 데이터의 자연적인 구조로 인한 결과이다. 데이터가 보간할 수 있는 매니폴드를 형성하는 경우에만 일반화할 수 있다. 특성이 유익하고 잡음이 적을수록 입력 공간이 더 간단하고 구조적이기 때문에 더 잘 일반화할 수 있다. 데이터 큐레이션(data curation)과 특성 공학(feature engineering)은 일반화에 필수적이다.<br/>
&ensp;또한 딥러닝이 곡선을 맞추는 것이기 때문에 모델이 이를 잘 수행하려면 입력 공간을 조밀하게 샘플링하여 훈련해야 한다. '조밀한 샘플링'은 다음과 같이 입력 데이터 매니폴드 전체를 조밀하게 커버해야 한다는 의미이다. 결정 근처에서는 특히 그러하다. 충분히 조밀하게 샘플링하면 상식, 요약, 추론 또는 세상에 대한 외부 지식을 사용하지 않아도 훈련 입력 사이를 보간하여 새로운 입력을 이해할 수 있다.<br/>
<p align="center"><img src="/assets/img/Deep Learning with Python/5장 머신 러닝의 기본 요소/1-9-조밀한 샘플링.png" width="400"></p>

&ensp;따라서 딥러닝 모델을 향상시키는 가장 좋은 방법은 더 좋고, 더 많은 데이터에서 훈련하는 것이다. 입력 데이터 매니폴드를 조밀하게커버하면 일반화 성능이 더 좋은 모델을 만든다. 딥러닝 모델이 훈련 샘플 사이를 단순히 보간하는 것 이상을 수행하리라고 기대하서는 안 된다. 따라서 가능한 쉽게 보간하기 위해 할 수 있는 모든 일을 해야한다. 딥러닝 모델에서 찾게 될 것은 무엇을 모델에 넣었는지에 달려 있다.<br/>
&ensp;데이터를 더 수집하는 것이 불가능하면 차선책은 모델이 저장할 수 있는 정보량을 조정하거나 모델 곡선의 매끄러운 정도에 제약을 추가하는 것이다. 네트워크가 적은 개수의 패턴만 기억하거나 매우 규칙적인 패턴만 기억할 수 있다면 최적화 과정은 일반화 가능성이 높은 가장 눈에 띄는 패턴만 모델의 초점을 맞추도록 할 것이다. 이런 방식으로 과대적합과 싸우는 과정을 **규체(regularization)**라고 한다. 일반화가 더 잘되도록 모델을 조정하기 전에 현재 모델이 어떻게 동작하는지 평가할 방법이 필요하다.

머신 러닝 모델 평가
======

&ensp;새로운 데이터에 성공적으로 일반화할 수 있는 모델을 개발하는 것이 목표이므로 모델의 일반화 성능을 신뢰 있게 측정할 수 있어야 한다.

훈련, 검증, 테스트 세트
------

&ensp;모델 평가의 핵심은 가용한 데이터를 항상 훈련, 검증, 테스트 3개의 세트로 나누는 것이다. 훈련 세트에서 모델을 훈련하고 검증 세트에서 모델을 평가한다. 모델을 출시할 준비가 되면 테스트 세트에서 최종적으로 딱 한 번 모델을 테스트한다. 테스트 데이터는 가능한 제품 환경의 데이터와 비슷해야 한다. 그다음 모델을 제품 환경에 배포한다. 훈련 세트와 테스트 세트 2개만 사용하면 훈련 세트에서 훈련하고 테스트 세트에서 평가하므로 간단하다.<br/>
&ensp;하지만 이처럼 하지 않는 이유는 모델을 개발할 때 항상 모델의 설정을 튜닝하기 때문이다. 예를 들어 층이나 층의 유닛 개수를 선택한다(**하이퍼파라미터(hyperparameter)**). 검증 세트에서 모델의 성능을 평가하여 이런 튜닝을 수행한다. 본질적으로 이런 튜닝도 어떤 파라미터 공간에서 조흔 설정을 찾는 **학습**이다. 검증 세트의 성능을 기반으로 모델의 설정을 튜닝하면 검증 세트로 모델을 직접 훈련하지 않더라고 빠르게 **검증 세트에 과대적합**될 수 있다.<br/>

훈련 성능 형성하기
======

일반화 성능 형성하기
======